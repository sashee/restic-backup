AWSTemplateFormatVersion: 2010-09-09
Parameters:
  ManagementAccountId:
    Type: String
    Description: "The account ID of the management account"
  NotificationSNSTopicArn:
    Type: String
    Description: "The topic that will be notified when the user is disabled"
  Monitors:
    Type: String
    Default: "base"
    Description: "Comma-separated list of available monitors"
  AlertIfMissedEventsForDays:
    Type: Number
    MinValue: 1
    Default: 3
    Description: "Send an alert if there were no successful backup in this amount of days"
  ReportInterval:
    Type: Number
    MinValue: 1
    Default: 30
    Description: "Send a report every <n> days"
  LambdaConcurrency:
    Type: Number
    MinValue: 0
    Default: 0
    Description: "Reserves (and limits) the lambdas to this amount of concurrency. Specify 0 to disable (no limit). Should set to 1 if the account has more than the minimum concurrency required, otherwise 0."

Conditions:
  SetLambdaConcurrency: !Not [!Equals [!Ref LambdaConcurrency, 0]]

Resources:
  Bucket:
    Type: AWS::S3::Bucket
    Properties:
      LifecycleConfiguration:
        Rules:
          - Status: Enabled
            AbortIncompleteMultipartUpload:
              DaysAfterInitiation: 180
            NoncurrentVersionExpiration:
              NoncurrentDays: 180
          - Status: Enabled
            Prefix: "data/"
            ObjectSizeGreaterThan: 1048576
            Transitions:
              - StorageClass: INTELLIGENT_TIERING
                TransitionInDays: 0
            NoncurrentVersionTransitions:
              - StorageClass: DEEP_ARCHIVE
                TransitionInDays: 0
      VersioningConfiguration:
        Status: Enabled
  BackupUser:
    Type: AWS::IAM::User
    Properties:
      Policies:
      - PolicyName: backup
        PolicyDocument:
           Version: 2012-10-17
           Statement:
              - Effect: Allow
                Action:
                 - 's3:ListBucket'
                 - 's3:GetBucketLocation'
                Resource: !GetAtt Bucket.Arn
              - Effect: Allow
                Action:
                 - 's3:GetObject'
                 - 's3:PutObject'
                 - 's3:DeleteObject'
                Resource: !Sub "${Bucket.Arn}/*"
  MonitoringUser:
    Type: AWS::IAM::User
    Properties:
      Policies:
      - PolicyName: backup
        PolicyDocument:
           Version: 2012-10-17
           Statement:
              - Effect: Allow
                Action:
                - 'lambda:InvokeFunctionUrl'
                Resource: !GetAtt MonitoringLambdaUrl.FunctionArn
# access denied disabler
  CloudTrailSNSTopic:
    Type: AWS::SNS::Topic
  SNSTopicPolicy:
    Type: AWS::SNS::TopicPolicy
    Properties:
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            AWS: !Ref ManagementAccountId
          Action: sns:Publish
          Resource: "*"
      Topics:
      - !Ref CloudTrailSNSTopic
  Queue: 
    Type: AWS::SQS::Queue
  QueuePolicy: 
    Type: AWS::SQS::QueuePolicy
    Properties: 
      Queues: 
        - !Ref Queue
      PolicyDocument: 
        Statement: 
          - Action: "sqs:SendMessage" 
            Effect: "Allow"
            Resource: !GetAtt Queue.Arn
            Principal:  
              Service: "sns.amazonaws.com"
            Condition:
              ArnEquals:
                "aws:SourceArn": !Ref CloudTrailSNSTopic
  SQSLogGroup: 
    Type: AWS::Logs::LogGroup
    Properties: 
      RetentionInDays: 365
  PipeRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - pipes.amazonaws.com
          Action:
          - sts:AssumeRole
          Condition:
            StringEquals:
              'aws:SourceArn': !Sub
                - 'arn:${AWS::Partition}:pipes:${AWS::Region}:${AWS::AccountId}:pipe/${PipeName}'
                - PipeName: !Select [2, !Split ['/', !Ref AWS::StackId]]
      Policies:
        - PolicyName: permissions
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
            - Effect: Allow
              Action:
              - 'sqs:ReceiveMessage'
              - 'sqs:DeleteMessage'
              - 'sqs:GetQueueAttributes'
              Resource: !GetAtt Queue.Arn
            - Effect: Allow
              Action:
              - 'logs:PutLogEvents'
              - 'logs:CreateLogStream'
              Resource: !Sub "${SQSLogGroup.Arn}:*"
  SQSToCloudWatchLogs:
    Type: 'AWS::Pipes::Pipe'
    Properties:
      Name: !Select [2, !Split ['/', !Ref AWS::StackId]]
      RoleArn: !GetAtt PipeRole.Arn
      Source: !GetAtt Queue.Arn
      Target: !GetAtt SQSLogGroup.Arn
      TargetParameters:
        InputTemplate: "<$.tody.Message>"
  QueueSubscription:
    Type: AWS::SNS::Subscription
    Properties:
      Endpoint: !GetAtt Queue.Arn
      Protocol: sqs
      TopicArn: !Ref CloudTrailSNSTopic
      FilterPolicyScope: MessageBody
      FilterPolicy:
        "$or":
          - errorCode:
            - AccessDenied
          - eventName:
            - GetCallerIdentity
        userIdentity:
          arn:
            - !GetAtt BackupUser.Arn
            - !GetAtt MonitoringUser.Arn
  DisablerLambdaLogGroup: 
    Type: AWS::Logs::LogGroup
    Properties: 
      RetentionInDays: 365
  DisablerLambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Policies:
        - PolicyName: permissions
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
            - Effect: Allow
              Action:
              - 'logs:PutLogEvents'
              - 'logs:CreateLogStream'
              Resource: !Sub "${DisablerLambdaLogGroup.Arn}:*"
            - Effect: Allow
              Action:
              - 'iam:AttachUserPolicy'
              Resource:
              - !GetAtt BackupUser.Arn
              - !GetAtt MonitoringUser.Arn
              Condition:
                StringEquals:
                  "iam:PolicyARN": "arn:aws:iam::aws:policy/AWSDenyAll"
            - Effect: Allow
              Action:
              - 'sns:Publish'
              Resource: !Ref NotificationSNSTopicArn
  DisablerLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      Runtime: nodejs20.x
      Role: !GetAtt DisablerLambdaExecutionRole.Arn
      Handler: index.handler
      ReservedConcurrentExecutions: !If [SetLambdaConcurrency, !Ref LambdaConcurrency, !Ref "AWS::NoValue"]
      Timeout: 30
      Code:
        ZipFile: |
          const {IAMClient, AttachUserPolicyCommand} = require("@aws-sdk/client-iam");
          const {SNSClient, PublishCommand} = require("@aws-sdk/client-sns");

          exports.handler = async (event) => {
            await new IAMClient().send(new AttachUserPolicyCommand({
              UserName: process.env.BackupUserName,
              PolicyArn: "arn:aws:iam::aws:policy/AWSDenyAll",
            }));
            await new IAMClient().send(new AttachUserPolicyCommand({
              UserName: process.env.MonitoringUserName,
              PolicyArn: "arn:aws:iam::aws:policy/AWSDenyAll",
            }));

            const client = new SNSClient({region: process.env.NotificationSNSTopicArn.split(":")[3]});
            await client.send(new PublishCommand({
              Message: `User disabled. Check logs at https://${process.env.AWS_REGION}.console.aws.amazon.com/cloudwatch/home#logsV2:log-groups/log-group/${process.env.SQSLogGroup.replaceAll("/", "$252F")}/log-events`,
              TopicArn: process.env.NotificationSNSTopicArn,
            }));
          };
      LoggingConfig:
        LogGroup: !Ref DisablerLambdaLogGroup
        LogFormat: JSON
      Environment:
        Variables:
          BackupUserName: !Ref BackupUser
          MonitoringUserName: !Ref MonitoringUser
          NotificationSNSTopicArn: !Ref NotificationSNSTopicArn
          SQSLogGroup: !Ref SQSLogGroup
  AccessDeniedAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      ComparisonOperator: GreaterThanThreshold
      EvaluationPeriods: 1
      Threshold: 0
      Namespace: "AWS/SQS"
      MetricName: "NumberOfMessagesSent"
      Dimensions:
        - Name: QueueName
          Value: !GetAtt Queue.QueueName
      Statistic: Maximum
      Period: 60
      TreatMissingData: notBreaching
      ActionsEnabled: true
      AlarmActions:
      - !GetAtt DisablerLambdaFunction.Arn
  InvokeDisablerLambdaPermission: 
    Type: AWS::Lambda::Permission
    Properties: 
      FunctionName: !GetAtt DisablerLambdaFunction.Arn
      Action: "lambda:InvokeFunction"
      Principal: "lambda.alarms.cloudwatch.amazonaws.com"
      SourceArn: !GetAtt AccessDeniedAlarm.Arn
# monitoring
  RunIDTable: 
    Type: AWS::DynamoDB::Table
    Properties: 
      AttributeDefinitions: 
        - AttributeName: "RunID"
          AttributeType: "S"
      KeySchema: 
        - AttributeName: "RunID"
          KeyType: "HASH"
      BillingMode: PAY_PER_REQUEST
      OnDemandThroughput:
        MaxReadRequestUnits: 5
        MaxWriteRequestUnits: 5
      TimeToLiveSpecification:
        AttributeName: ttl
        Enabled: true
  RunsTable: 
    Type: AWS::DynamoDB::Table
    Properties: 
      AttributeDefinitions: 
        - AttributeName: "InternalID"
          AttributeType: "S"
        - AttributeName: "Monitor"
          AttributeType: "S"
        - AttributeName: "StartTime"
          AttributeType: "N"
      KeySchema: 
        - AttributeName: "InternalID"
          KeyType: "HASH"
      BillingMode: PAY_PER_REQUEST
      OnDemandThroughput:
        MaxReadRequestUnits: 5
        MaxWriteRequestUnits: 5
      TimeToLiveSpecification:
        AttributeName: ttl
        Enabled: true
      GlobalSecondaryIndexes: 
        - IndexName: "ByMonitor"
          KeySchema: 
            - AttributeName: "Monitor"
              KeyType: "HASH"
            - AttributeName: "StartTime"
              KeyType: "RANGE"
          OnDemandThroughput:
            MaxReadRequestUnits: 5
            MaxWriteRequestUnits: 5
          Projection: 
            ProjectionType: "ALL"
  LogsTable: 
    Type: AWS::DynamoDB::Table
    Properties: 
      AttributeDefinitions: 
        - AttributeName: "InternalID#Label"
          AttributeType: "S"
      KeySchema: 
        - AttributeName: "InternalID#Label"
          KeyType: "HASH"
      BillingMode: PAY_PER_REQUEST
      OnDemandThroughput:
        MaxReadRequestUnits: 5
        MaxWriteRequestUnits: 5
      TimeToLiveSpecification:
        AttributeName: ttl
        Enabled: true
  MonitoringLambdaLogGroup: 
    Type: AWS::Logs::LogGroup
    Properties: 
      RetentionInDays: 365
  MonitoringLambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Policies:
        - PolicyName: permissions
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
            - Effect: Allow
              Action:
              - 'logs:PutLogEvents'
              - 'logs:CreateLogStream'
              Resource: !Sub "${MonitoringLambdaLogGroup.Arn}:*"
            - Effect: Allow
              Action:
              - 'dynamodb:GetItem'
              - 'dynamodb:PutItem'
              Resource: !GetAtt RunIDTable.Arn
            - Effect: Allow
              Action:
              - 'dynamodb:PutItem'
              - 'dynamodb:UpdateItem'
              Resource: !GetAtt RunsTable.Arn
            - Effect: Allow
              Action:
              - 'dynamodb:PutItem'
              Resource: !GetAtt LogsTable.Arn
  MonitoringLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      Runtime: nodejs20.x
      Role: !GetAtt MonitoringLambdaExecutionRole.Arn
      Handler: index.handler
      ReservedConcurrentExecutions: !If [SetLambdaConcurrency, !Ref LambdaConcurrency, !Ref "AWS::NoValue"]
      Timeout: 30
      Code:
        ZipFile: |
          const {DynamoDBClient, GetItemCommand, PutItemCommand, UpdateItemCommand} = require("@aws-sdk/client-dynamodb");
          const crypto = require("crypto");
          const zlib = require("node:zlib");
          const {promisify} = require("node:util");

          exports.handler = async (event) => {
            const {body, ...rest} = event;
            console.log({...rest, bodyLength: body?.length});
            const client = new DynamoDBClient();
            if (event.requestContext.http.path === "/run") {
              const {runid, monitor} = event.queryStringParameters;
              const internalId = crypto.randomUUID();
              console.log({message: "starting monitoring run", internalId});
              try {
                if (!process.env.Monitors.split(",").includes(monitor)) {
                  throw new Error(`Monitor not defined: ${monitor}`);
                };
                await client.send(new PutItemCommand({
                  TableName: process.env.RunIDTable,
                  Item: {
                    RunID: {S: runid},
                    InternalID: {S: internalId},
                    Monitor: {S: monitor},
                    ttl: {N: String(Math.round((new Date().getTime() + 365 * 24 * 60 * 60 * 1000) / 1000))},
                  },
                  ConditionExpression: "attribute_not_exists(#pk)",
                  ExpressionAttributeNames: {
                    "#pk": "RunID",
                  },
                }));
                await client.send(new PutItemCommand({
                  TableName: process.env.RunsTable,
                  Item: {
                    InternalID: {S: internalId},
                    StartTime: {N: String(new Date().getTime())},
                    Monitor: {S: monitor},
                    ttl: {N: String(Math.round((new Date().getTime() + 365 * 24 * 60 * 60 * 1000) / 1000))},
                  },
                  ConditionExpression: "attribute_not_exists(#pk)",
                  ExpressionAttributeNames: {
                    "#pk": "InternalID",
                  },
                }));
              }catch(e) {
                console.log({message: "starting monitoring run: error", internalId, e});
                throw e;
              }
            } else if (event.requestContext.http.path === "/log") {
              const {runid, label} = event.queryStringParameters;
              const bodyBuffer = Buffer.from(body, event.isBase64Encoded ? "base64" : "utf8");

              const item = await client.send(new GetItemCommand({
                TableName: process.env.RunIDTable,
                Key: {
                  RunID: {S: runid},
                },
              }));
              const internalId = item.Item.InternalID.S;
              console.log({message: "logging", internalId});

              const compressed = await promisify(zlib.brotliCompress)(bodyBuffer, {params: {
                [zlib.constants.BROTLI_PARAM_MODE]: zlib.constants.BROTLI_MODE_TEXT,
                [zlib.constants.BROTLI_PARAM_QUALITY]: zlib.constants.BROTLI_MAX_QUALITY,
                [zlib.constants.BROTLI_PARAM_SIZE_HINT]: bodyBuffer.length,
              }});
              console.log({type: "compressed", original: bodyBuffer.length, compressed: compressed.length});
              await client.send(new PutItemCommand({
                TableName: process.env.LogsTable,
                Item: {
                  "InternalID#Label": {S: `${internalId}#${label}`},
                  InternalID: {S: internalId},
                  Label: {S: label},
                  Time: {N: String(new Date().getTime())},
                  Message: {B: compressed},
                  ttl: {N: String(Math.round((new Date().getTime() + 365 * 24 * 60 * 60 * 1000) / 1000))},
                },
                ConditionExpression: "attribute_not_exists(#pk)",
                ExpressionAttributeNames: {
                  "#pk": "InternalID#Label",
                },
              }));
            } else if (["/success", "/fail"].includes(event.requestContext.http.path)) {
              const {runid} = event.queryStringParameters;
              const item = await client.send(new GetItemCommand({
                TableName: process.env.RunIDTable,
                Key: {
                  RunID: {S: runid},
                },
              }));
              const internalId = item.Item.InternalID.S;
              console.log({message: "finishing monitoring run", internalId});
              try {
                await client.send(new UpdateItemCommand({
                  TableName: process.env.RunsTable,
                  Key: {
                    InternalID: {S: internalId},
                  },
                  ConditionExpression: "attribute_exists(#pk) and attribute_not_exists(#Success)",
                  UpdateExpression: "SET #EndTime = :EndTime, #Success = :Success",
                  ExpressionAttributeNames: {
                    "#pk": "InternalID",
                    "#EndTime": "EndTime",
                    "#Success": "Success",
                  },
                  ExpressionAttributeValues: {
                    ":EndTime": {N: String(new Date().getTime())},
                    ":Success": {BOOL: String(event.requestContext.http.path === "/success")},
                  },
                }));
              }catch(e) {
                console.log({message: "finishing: error", internalId, e});
                throw e;
              }
            }else {
              throw new Error("Path not exists");
            }
          };
      LoggingConfig:
        LogGroup: !Ref MonitoringLambdaLogGroup
        LogFormat: JSON
      Environment:
        Variables:
          RunIDTable: !GetAtt RunIDTable.Arn
          RunsTable: !GetAtt RunsTable.Arn
          LogsTable: !GetAtt LogsTable.Arn
          Monitors: !Ref Monitors
  MonitoringLambdaUrl:
    Type: AWS::Lambda::Url
    Properties:
      AuthType: AWS_IAM
      TargetFunctionArn: !GetAtt MonitoringLambdaFunction.Arn
# alerting lambda
  AlertingLambdaLogGroup: 
    Type: AWS::Logs::LogGroup
    Properties: 
      RetentionInDays: 365
  AlertingLambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Policies:
        - PolicyName: permissions
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
            - Effect: Allow
              Action:
              - 'logs:PutLogEvents'
              - 'logs:CreateLogStream'
              Resource: !Sub "${AlertingLambdaLogGroup.Arn}:*"
            - Effect: Allow
              Action:
              - 'dynamodb:Query'
              Resource: !Sub "${RunsTable.Arn}/index/ByMonitor"
            - Effect: Allow
              Action:
              - 'dynamodb:PutItem'
              Resource: !GetAtt ReportTokensTable.Arn
            - Effect: Allow
              Action:
              - 'sns:Publish'
              Resource: !Ref NotificationSNSTopicArn
  AlertingLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      Runtime: nodejs20.x
      Role: !GetAtt AlertingLambdaExecutionRole.Arn
      Handler: index.handler
      ReservedConcurrentExecutions: !If [SetLambdaConcurrency, !Ref LambdaConcurrency, !Ref "AWS::NoValue"]
      Timeout: 30
      Code:
        ZipFile: |
          const {DynamoDBClient, QueryCommand, PutItem, paginateQuery} = require("@aws-sdk/client-dynamodb");
          const {SNSClient, PublishCommand} = require("@aws-sdk/client-sns");

          exports.handler = async (event) => {
            console.log(event);
            const endTime = new Date(event.scheduledTime);
            const startTime = new Date(endTime.getTime() - process.env.AlertIfMissedEventsForDays * 1000 * 60 * 60 * 24);
            console.log({endTime, startTime});
            const client = new DynamoDBClient();
            const monitorItems = await Promise.all(process.env.Monitors.split(",").map(async (monitor) => {
              const items = [];
              for await (const page of paginateQuery({client}, {
                TableName: process.env.RunsTable,
                IndexName: "ByMonitor",
                KeyConditionExpression: "#Monitor = :monitor and #StartTime between :startTime and :endTime",
                ExpressionAttributeNames: {
                  "#Monitor": "Monitor",
                  "#StartTime": "StartTime",
                },
                ExpressionAttributeValues: {
                  ":monitor": {S: monitor},
                  ":startTime": {N: String(startTime.getTime())},
                  ":endTime": {N: String(endTime.getTime())},
                },
              })) {
                items.push(...page.Items);
              }
              return {monitor, items};
            }));
            const monitorErrors = monitorItems.filter(({items}) => !items.some((item) => item.Success.BOOL));
            if (monitorErrors.length > 0) {
              console.log(monitorErrors);

              const token = crypto.randomUUID();
              await client.send(new PutItemCommand({
                TableName: process.env.ReportTokensTable,
                Item: {
                  Token: {S: token},
                  StartTime: {N: String(startTime.getTime())},
                  EndTime: {N: String(endTime.getTime())},
                  ttl: {N: String(Math.round((new Date().getTime() + 365 * 24 * 60 * 60 * 1000) / 1000))},
                },
                ConditionExpression: "attribute_not_exists(#pk)",
                ExpressionAttributeNames: {
                  "#pk": "RunID",
                },
              }));
              const reportingUrl = `${event.functionUrl}?token=${token}`;

              const snsClient = new SNSClient({region: process.env.NotificationSNSTopicArn.split(":")[3]});
              await snsClient.send(new PublishCommand({
                Message: `Some monitors did not report success in the past ${process.env.AlertIfMissedEventsForDays} day(s): ${monitorErrors.map(({monitor}) => monitor)}. Check the full report: ${reportingUrl}`,
                TopicArn: process.env.NotificationSNSTopicArn,
              }));
            }
          };
      LoggingConfig:
        LogGroup: !Ref AlertingLambdaLogGroup
        LogFormat: JSON
      Environment:
        Variables:
          RunsTable: !GetAtt RunsTable.Arn
          Monitors: !Ref Monitors
          AlertIfMissedEventsForDays: !Ref AlertIfMissedEventsForDays
          ReportTokensTable: !GetAtt ReportTokensTable.Arn
          NotificationSNSTopicArn: !Ref NotificationSNSTopicArn
  AlertingSchedule:
    Type: AWS::Scheduler::Schedule
    Properties:
      FlexibleTimeWindow: 
        Mode: "OFF"
      ScheduleExpression: "rate(1 day)"
      Target: 
        Arn: !GetAtt AlertingLambdaFunction.Arn
        Input: !Sub '{"scheduledTime": "<aws.scheduler.scheduled-time>", "functionUrl": "${ReportingLambdaUrl.FunctionUrl}"}'
        RoleArn: !GetAtt AlertingScheduleRole.Arn
  AlertingScheduleRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - scheduler.amazonaws.com
          Action:
          - sts:AssumeRole
      Policies:
        - PolicyName: permissions
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
            - Effect: Allow
              Action:
              - 'lambda:InvokeFunction'
              Resource: !GetAtt AlertingLambdaFunction.Arn
# reporting lambda
  ReportTokensTable: 
    Type: AWS::DynamoDB::Table
    Properties: 
      AttributeDefinitions: 
        - AttributeName: "Token"
          AttributeType: "S"
      KeySchema: 
        - AttributeName: "Token"
          KeyType: "HASH"
      BillingMode: PAY_PER_REQUEST
      OnDemandThroughput:
        MaxReadRequestUnits: 5
        MaxWriteRequestUnits: 5
      TimeToLiveSpecification:
        AttributeName: ttl
        Enabled: true
  ReportingLambdaLogGroup: 
    Type: AWS::Logs::LogGroup
    Properties: 
      RetentionInDays: 365
  ReportingLambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Policies:
        - PolicyName: permissions
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
            - Effect: Allow
              Action:
              - 'logs:PutLogEvents'
              - 'logs:CreateLogStream'
              Resource: !Sub "${ReportingLambdaLogGroup.Arn}:*"
            - Effect: Allow
              Action:
              - 'dynamodb:Query'
              Resource: !Sub "${RunsTable.Arn}/index/ByMonitor"
            - Effect: Allow
              Action:
              - 'dynamodb:GetItem'
              Resource: !GetAtt LogsTable.Arn
            - Effect: Allow
              Action:
              - 'dynamodb:GetItem'
              - 'dynamodb:PutItem'
              Resource: !GetAtt ReportTokensTable.Arn
            - Effect: Allow
              Action:
              - 'sns:Publish'
              Resource: !Ref NotificationSNSTopicArn
  ReportingLambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      Runtime: nodejs20.x
      Role: !GetAtt ReportingLambdaExecutionRole.Arn
      Handler: index.handler
      ReservedConcurrentExecutions: !If [SetLambdaConcurrency, !Ref LambdaConcurrency, !Ref "AWS::NoValue"]
      Timeout: 30
      Code:
        ZipFile: |
          const {DynamoDBClient, QueryCommand, PutItemCommand, paginateQuery, GetItemCommand} = require("@aws-sdk/client-dynamodb");
          const {SNSClient, PublishCommand} = require("@aws-sdk/client-sns");
          const crypto = require("crypto");
          const zlib = require("node:zlib");
          const {promisify} = require("node:util");

          const getLog = (client) => async (internalId, label) => {
            const item = await client.send(new GetItemCommand({
              TableName: process.env.LogsTable,
              Key: {
                "InternalID#Label": {S: `${internalId}#${label}`},
              },
            }));
            if (item.Item) {
              const message = Buffer.from(item.Item.Message.B);
              const decompressed = await promisify(zlib.brotliDecompress)(message);
              return decompressed.toString();
            }else {
              return undefined;
            }
          }

          const getEvents = (client) => async (startTime, endTime) => {
            return Promise.all(process.env.Monitors.split(",").map(async (monitor) => {
              const results = [];
              for await (const page of paginateQuery({client}, {
                TableName: process.env.RunsTable,
                IndexName: "ByMonitor",
                KeyConditionExpression: "#Monitor = :monitor and #StartTime between :startTime and :endTime",
                ExpressionAttributeNames: {
                  "#Monitor": "Monitor",
                  "#StartTime": "StartTime",
                },
                ExpressionAttributeValues: {
                  ":monitor": {S: monitor},
                  ":startTime": {N: String(startTime.getTime())},
                  ":endTime": {N: String(endTime.getTime())},
                },
              })) {
                const res = await Promise.all(page.Items.map(async (item) => {
                  const [
                    version,
                    versionError,
                    unlock,
                    unlockError,
                    backup,
                    backupError,
                    forget,
                    forgetError,
                    prune,
                    pruneError,
                    check,
                    checkError,
                    snapshots,
                    snapshotsError,
                    stats,
                    statsError,
                  ] = await Promise.all([
                    getLog(client)(item.InternalID.S, "version"),
                    getLog(client)(item.InternalID.S, "version-error"),
                    getLog(client)(item.InternalID.S, "unlock"),
                    getLog(client)(item.InternalID.S, "unlock-error"),
                    getLog(client)(item.InternalID.S, "backup"),
                    getLog(client)(item.InternalID.S, "backup-error"),
                    getLog(client)(item.InternalID.S, "forget"),
                    getLog(client)(item.InternalID.S, "forget-error"),
                    getLog(client)(item.InternalID.S, "prune"),
                    getLog(client)(item.InternalID.S, "prune-error"),
                    getLog(client)(item.InternalID.S, "check"),
                    getLog(client)(item.InternalID.S, "check-error"),
                    getLog(client)(item.InternalID.S, "snapshots"),
                    getLog(client)(item.InternalID.S, "snapshots-error"),
                    getLog(client)(item.InternalID.S, "stats"),
                    getLog(client)(item.InternalID.S, "stats-error"),
                  ]);

                  const safeRun = (fn) => {
                    try {
                      return fn();
                    }catch(e) {
                      console.error(e);
                    }
                  };

                  const rawLogs = {
                    version: safeRun(() => JSON.parse(version)),
                    "version-error": safeRun(() => JSON.parse(versionError)),
                    unlock: safeRun(() => JSON.parse(unlock)),
                    "unlock-error": safeRun(() => JSON.parse(unlockError)),
                    backup: safeRun(() => JSON.parse(backup)),
                    "backup-error": safeRun(() => JSON.parse(backupError)),
                    forget: safeRun(() => JSON.parse(forget)),
                    "forget-error": safeRun(() => JSON.parse(forgetError)),
                    prune: safeRun(() => JSON.parse(prune)),
                    "prune-error": safeRun(() => JSON.parse(pruneError)),
                    check: safeRun(() => JSON.parse(check)),
                    "check-error": safeRun(() => JSON.parse(checkError)),
                    snapshots: safeRun(() => JSON.parse(snapshots)),
                    "snapshots-error": safeRun(() => JSON.parse(snapshotsError)),
                    stats: safeRun(() => JSON.parse(stats)),
                    "stats-error": safeRun(() => JSON.parse(statsError)),
                  };
                  const anyErrors = versionError || unlockError || backupError || forgetError || pruneError || checkError || snapshotsError || statsError;
                  if (item.Success?.BOOL) {
                    // success
                    const versionString = safeRun(() => {
                      if (version) {
                        const versionJson = JSON.parse(version);
                        return `${versionJson.stdout.packageVersion} (${versionJson.stdout.resticVersion} ; ${versionJson.stdout.nodeVersion})`;
                      }
                    });
                    const backupStats = safeRun(() => {
                      if (backup) {
                        const statsJson = JSON.parse(stats);
                        return {
                          total_size: statsJson.stdout.total_size,
                          total_file_count: statsJson.stdout.total_file_count,
                        }
                      }
                    });
                    return {
                      status: "SUCCESS",
                      startTime: new Date(Number(item.StartTime.N)),
                      endTime: new Date(Number(item.EndTime.N)),
                      versionString,
                      backupStats,
                      anyErrors,
                      rawLogs,
                    };
                  }else if (item.Success){
                    // failed
                    return {
                      status: "FAILED",
                      startTime: new Date(Number(item.StartTime.N)),
                      endTime: new Date(Number(item.EndTime.N)),
                      rawLogs,
                    };
                  }else {
                    // pending
                    return {
                      status: "PENDING",
                      startTime: new Date(Number(item.StartTime.N)),
                      anyErrors,
                      rawLogs,
                    };
                  }
                }));
                results.push(...res);
              }
              console.log({monitor, results});
              return {monitor, results};
            }));
          }

          exports.handler = async (event) => {
            console.log(event);
            const client = new DynamoDBClient();
            if (event.scheduledTime && event.functionUrl) {
              // called by schedule, send email
              const endTime = new Date(event.scheduledTime);
              const startTime = new Date(endTime.getTime() - process.env.ReportInterval * 1000 * 60 * 60 * 24);
              console.log({endTime, startTime});
              const monitorEvents = await getEvents(client)(startTime, endTime);
              const token = crypto.randomUUID();
              await client.send(new PutItemCommand({
                TableName: process.env.ReportTokensTable,
                Item: {
                  Token: {S: token},
                  StartTime: {N: String(startTime.getTime())},
                  EndTime: {N: String(endTime.getTime())},
                  ttl: {N: String(Math.round((new Date().getTime() + 365 * 24 * 60 * 60 * 1000) / 1000))},
                },
                ConditionExpression: "attribute_not_exists(#pk)",
                ExpressionAttributeNames: {
                  "#pk": "RunID",
                },
              }));
              const reportingUrl = `${event.functionUrl}?token=${token}`;
              await client.send(new PublishCommand({
                Message: `Report ready. Check the full report: ${reportingUrl}`,
                TopicArn: process.env.NotificationSNSTopicArn,
              }));
            }else {
              // called with token through Url, return HTML
              const token = event.queryStringParameters?.token;
              if (!token) {
                return {statusCode: 404};
              }
              const item = await client.send(new GetItemCommand({
                TableName: process.env.ReportTokensTable,
                Key: {
                  Token: {S: token},
                },
              }));
              if (!item) {
                return {statusCode: 404};
              }
              const startTime = new Date(Number(item.Item.StartTime.N));
              const endTime = new Date(Number(item.Item.EndTime.N));
              const monitorEvents = await getEvents(client)(startTime, endTime);
              const encodeResponse = async (body) => {
                const acceptEncoding = event.headers["accept-encoding"];
                if (acceptEncoding && acceptEncoding.split(",").some((v) => v.split(";")[0].trim() === "br")) {
                  const bodyBuffer = Buffer.from(body, "utf8");
                  const compressedBody = await promisify(zlib.brotliCompress)(bodyBuffer, {params: {
                    [zlib.constants.BROTLI_PARAM_MODE]: zlib.constants.BROTLI_MODE_TEXT,
                    [zlib.constants.BROTLI_PARAM_QUALITY]: zlib.constants.BROTLI_MAX_QUALITY,
                    [zlib.constants.BROTLI_PARAM_SIZE_HINT]: bodyBuffer.length,
                  }});
                  return {
                    headers: {
                      "Content-Encoding": "br",
                    },
                    isBase64Encoded: true,
                    body: compressedBody.toString("base64"),
                  };
                }else {
                  return {
                    headers: {},
                    isBase64Encoded: false,
                    body,
                  }
                }
              };
              const body = `<html><body><pre>${JSON.stringify(monitorEvents, undefined, 4)}</pre></body></html>`;
              const encodedResponse = await encodeResponse(body);
              return {
                statusCode: 200,
                headers: {
                  ...encodedResponse.headers,
                  "Content-Type": "text/html",
                },
                isBase64Encoded: encodedResponse.isBase64Encoded,
                body: encodedResponse.body,
              };
            }
          };
      LoggingConfig:
        LogGroup: !Ref ReportingLambdaLogGroup
        LogFormat: JSON
      Environment:
        Variables:
          RunsTable: !GetAtt RunsTable.Arn
          LogsTable: !GetAtt LogsTable.Arn
          ReportTokensTable: !GetAtt ReportTokensTable.Arn
          Monitors: !Ref Monitors
          ReportInterval: !Ref ReportInterval
          NotificationSNSTopicArn: !Ref NotificationSNSTopicArn
  ReportingSchedule:
    Type: AWS::Scheduler::Schedule
    Properties:
      FlexibleTimeWindow: 
        Mode: "OFF"
      ScheduleExpression: !Sub "rate(${ReportInterval} days)"
      Target: 
        Arn: !GetAtt ReportingLambdaFunction.Arn
        Input: !Sub '{"scheduledTime": "<aws.scheduler.scheduled-time>", "functionUrl": "${ReportingLambdaUrl.FunctionUrl}"}'
        RoleArn: !GetAtt ReportingScheduleRole.Arn
  ReportingScheduleRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service:
            - scheduler.amazonaws.com
          Action:
          - sts:AssumeRole
      Policies:
        - PolicyName: permissions
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
            - Effect: Allow
              Action:
              - 'lambda:InvokeFunction'
              Resource: !GetAtt ReportingLambdaFunction.Arn
  ReportingLambdaUrl:
    Type: AWS::Lambda::Url
    Properties:
      AuthType: NONE
      TargetFunctionArn: !GetAtt ReportingLambdaFunction.Arn
  ReportingLambdaUrlInvokePermission:
     Type: AWS::Lambda::Permission
     Properties:
       FunctionName: !Ref ReportingLambdaFunction
       FunctionUrlAuthType: 'NONE'
       Action: lambda:InvokeFunctionUrl
       Principal: '*'
Outputs:
  CloudTrailSNSTopic:
    Value: !GetAtt CloudTrailSNSTopic.TopicArn
  AccessDeniedLogs:
    Value: !Sub
      - "https://${AWS::Region}.console.aws.amazon.com/cloudwatch/home#logsV2:log-groups/log-group/${CloudTrailLogsEscaped}/log-events"
      - CloudTrailLogsEscaped: !Join [ '$252F', !Split [ '/', !Ref SQSLogGroup ] ]
  MonitoringUrl:
    Value: !GetAtt MonitoringLambdaUrl.FunctionUrl
  MonitoringRegion:
    Value: !Ref AWS::Region
  Bucket:
    Value: !GetAtt Bucket.Arn
  BackupUser:
    Value: !Ref BackupUser
  MonitoringUser:
    Value: !Ref MonitoringUser
  ResticRepository:
    Value: !Sub "s3.dualstack.${AWS::Region}.amazonaws.com/${Bucket}"
  Version:
    Value: "<<VERSION_PLACEHOLDER>>"
